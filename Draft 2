import math
import numpy as np
import pandas as pd
import re
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm.auto import tqdm
import sklearn.metrics as metrics
from sklearn.dummy import DummyClassifier
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from lightgbm import LGBMClassifier
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
import torch
import transformers

# Ensure that the NLTK resources are downloaded
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('punkt')

# Load the stop words and lemmatizer from NLTK
nltk_stopwords = stopwords.words('english')
lemmatizer = WordNetLemmatizer()

# Load the dataset
df_reviews = pd.read_csv('https://practicum-content.s3.us-west-1.amazonaws.com/datasets/imdb_reviews.tsv', sep='\t', dtype={'votes': 'Int64'})

# Normalize text function
def normalize_text(text):
    text = text.lower()
    text = re.sub(r'\d+', '', text)
    text = re.sub(r'[^\w\s]', '', text)
    return ' '.join(text.split())

# Preprocess text function
def preprocess_text(text):
    tokens = nltk.word_tokenize(text)
    lemmatized_tokens = [lemmatizer.lemmatize(token.lower()) for token in tokens if token.isalpha() and token.lower() not in nltk_stopwords]
    return ' '.join(lemmatized_tokens)

# Apply normalization and preprocessing
df_reviews['review_norm'] = df_reviews['review'].apply(normalize_text)
df_reviews['processed_review'] = df_reviews['review'].apply(preprocess_text)

# Split the data into training and testing sets
df_reviews_train = df_reviews.query('ds_part == "train"').copy()
df_reviews_test = df_reviews.query('ds_part == "test"').copy()

train_target = df_reviews_train['pos']
test_target = df_reviews_test['pos']

# Function to evaluate models
def evaluate_model(model, train_features, train_target, test_features, test_target):
    eval_stats = {}
    fig, axs = plt.subplots(1, 3, figsize=(20, 6))

    for type, features, target in (('train', train_features, train_target), ('test', test_features, test_target)):
        eval_stats[type] = {}
        pred_target = model.predict(features)
        pred_proba = model.predict_proba(features)[:, 1]

        # F1 Score
        f1_thresholds = np.arange(0, 1.01, 0.05)
        f1_scores = [metrics.f1_score(target, pred_proba >= threshold) for threshold in f1_thresholds]

        # ROC
        fpr, tpr, roc_thresholds = metrics.roc_curve(target, pred_proba)
        roc_auc = metrics.roc_auc_score(target, pred_proba)
        eval_stats[type]['ROC AUC'] = roc_auc

        # PRC
        precision, recall, pr_thresholds = metrics.precision_recall_curve(target, pred_proba)
        aps = metrics.average_precision_score(target, pred_proba)
        eval_stats[type]['APS'] = aps

        color = 'blue' if type == 'train' else 'green'

        # Plot F1 Score
        ax = axs[0]
        max_f1_score_idx = np.argmax(f1_scores)
        ax.plot(f1_thresholds, f1_scores, color=color, label=f'{type}, max={f1_scores[max_f1_score_idx]:.2f} @ {f1_thresholds[max_f1_score_idx]:.2f}')
        for threshold in (0.2, 0.4, 0.5, 0.6, 0.8):
            closest_value_idx = np.argmin(np.abs(f1_thresholds - threshold))
            marker_color = 'orange' if threshold != 0.5 else 'red'
            ax.plot(f1_thresholds[closest_value_idx], f1_scores[closest_value_idx], color=marker_color, marker='X', markersize=7)
        ax.set_xlim([-0.02, 1.02])
        ax.set_ylim([-0.02, 1.02])
        ax.set_xlabel('threshold')
        ax.set_ylabel('F1')
        ax.legend(loc='lower center')
        ax.set_title('F1 Score')

        # Plot ROC
        ax = axs[1]
        ax.plot(fpr, tpr, color=color, label=f'{type}, ROC AUC={roc_auc:.2f}')
        for threshold in (0.2, 0.4, 0.5, 0.6, 0.8):
            closest_value_idx = np.argmin(np.abs(roc_thresholds - threshold))
            marker_color = 'orange' if threshold != 0.5 else 'red'
            ax.plot(fpr[closest_value_idx], tpr[closest_value_idx], color=marker_color, marker='X', markersize=7)
        ax.plot([0, 1], [0, 1], color='grey', linestyle='--')
        ax.set_xlim([-0.02, 1.02])
        ax.set_ylim([-0.02, 1.02])
        ax.set_xlabel('FPR')
        ax.set_ylabel('TPR')
        ax.legend(loc='lower center')
        ax.set_title('ROC Curve')

        # Plot PRC
        ax = axs[2]
        ax.plot(recall, precision, color=color, label=f'{type}, AP={aps:.2f}')
        for threshold in (0.2, 0.4, 0.5, 0.6, 0.8):
            closest_value_idx = np.argmin(np.abs(pr_thresholds - threshold))
            marker_color = 'orange' if threshold != 0.5 else 'red'
            ax.plot(recall[closest_value_idx], precision[closest_value_idx], color=marker_color, marker='X', markersize=7)
        ax.set_xlim([-0.02, 1.02])
        ax.set_ylim([-0.02, 1.02])
        ax.set_xlabel('recall')
        ax.set_ylabel('precision')
        ax.legend(loc='lower center')
        ax.set_title('PRC')

        eval_stats[type]['Accuracy'] = metrics.accuracy_score(target, pred_target)
        eval_stats[type]['F1'] = metrics.f1_score(target, pred_target)

    df_eval_stats = pd.DataFrame(eval_stats).round(2).reindex(index=('Accuracy', 'F1', 'APS', 'ROC AUC'))
    print(df_eval_stats)

# Vectorization and model training
vectorizer = TfidfVectorizer(stop_words=nltk_stopwords)
vectorizer.fit(df_reviews_train['processed_review'])

train_features = vectorizer.transform(df_reviews_train['processed_review'])
test_features = vectorizer.transform(df_reviews_test['processed_review'])

# Initialize and train the Logistic Regression model
model_lr = LogisticRegression()
model_lr.fit(train_features, train_target)

# Evaluate the Logistic Regression model
evaluate_model(model_lr, train_features, train_target, test_features, test_target)

# Initialize and train the LGBMClassifier model
model_lgbm = LGBMClassifier()
model_lgbm.fit(train_features, train_target)

# Evaluate the LGBMClassifier model
evaluate_model(model_lgbm, train_features, train_target, test_features, test_target)

# BERT embeddings
tokenizer = transformers.BertTokenizerFast.from_pretrained('bert-base-uncased')
model_bert = transformers.BertModel.from_pretrained('bert-base-uncased')

def BERT_text_to_embeddings(texts, max_length=512, batch_size=250, force_device=None, disable_progress_bar=False):
    encodings = tokenizer(texts, max_length=max_length, padding='max_length', truncation=True, return_tensors='pt')
    ids_list = encodings['input_ids']
    attention_mask_list = encodings['attention_mask']
    device = torch.device(force_device) if force_device else torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model_bert.to(device)

    embeddings = []
    for i in tqdm(range(math.ceil(len(ids_list) / batch_size)), disable=disable_progress_bar):
        ids_batch = ids_list[batch_size * i:batch_size * (i + 1)].to(device)
        attention_mask_batch = attention_mask_list[batch_size * i:batch_size * (i + 1)].to(device)
        with torch.no_grad():
            model_bert.eval()
            batch_embeddings = model_bert(input_ids=ids_batch, attention_mask=attention_mask_batch)
        embeddings.append(batch_embeddings[0][:, 0, :].detach().cpu().numpy())

    return np.concatenate(embeddings)

# Get embeddings for train and test sets
train_reviews = df_reviews_train['review'].astype(str).tolist()
test_reviews = df_reviews_test['review'].astype(str).tolist()

train_features_bert = BERT_text_to_embeddings(train_reviews)
test_features_bert = BERT_text_to_embeddings(test_reviews)

# Initialize and train the LGBMClassifier model with BERT features
model_bert_lgbm = LGBMClassifier()
model_bert_lgbm.fit(train_features_bert, train_target)

# Evaluate the LGBMClassifier model with BERT features
evaluate_model(model_bert_lgbm, train_features_bert, train_target, test_features_bert, test_target)
