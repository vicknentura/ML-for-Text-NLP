# Graph embeddings with Node2Vec

pip install networkx gensim

import networkx as nx
from gensim.models import Word2Vec

# Create a simple graph
G = nx.Graph()
edges = [('word1', 'word2'), ('word2', 'word3'), ('word1', 'word3'), ('word3', 'word4')]
G.add_edges_from(edges)

# Generate random walks
def random_walk(graph, start_node, walk_length):
    walk = [start_node]
    for _ in range(walk_length - 1):
        neighbors = list(graph.neighbors(walk[-1]))
        if neighbors:
            walk.append(random.choice(neighbors))
        else:
            break
    return walk

def generate_walks(graph, num_walks, walk_length):
    walks = []
    for _ in range(num_walks):
        for node in graph.nodes():
            walks.append(random_walk(graph, node, walk_length))
    return walks

# Generate walks
walks = generate_walks(G, num_walks=10, walk_length=5)

# Train Word2Vec model
model = Word2Vec(walks, vector_size=2, window=3, min_count=1, sg=1)

# Get embeddings
word1_embedding = model.wv['word1']
print("Embedding for 'word1':", word1_embedding)



# Community Detection

pip install python-louvain

import community as community_louvain
import matplotlib.pyplot as plt

# Create a simple graph
G = nx.Graph()
edges = [('word1', 'word2'), ('word2', 'word3'), ('word1', 'word3'), ('word3', 'word4')]
G.add_edges_from(edges)

# Apply Louvain method for community detection
partition = community_louvain.best_partition(G)

# Draw the graph with communities
pos = nx.spring_layout(G)
cmap = plt.get_cmap('viridis', max(partition.values()) + 1)
nx.draw(G, pos, node_color=list(partition.values()), cmap=cmap, with_labels=True)
plt.show()



# Link Prediction

from sklearn.metrics import roc_auc_score
import numpy as np

# Create a simple graph
G = nx.Graph()
edges = [('word1', 'word2'), ('word2', 'word3'), ('word1', 'word3'), ('word3', 'word4')]
G.add_edges_from(edges)

# Generate positive and negative samples
positive_samples = list(G.edges())
negative_samples = []
while len(negative_samples) < len(positive_samples):
    u, v = np.random.choice(G.nodes(), 2)
    if not G.has_edge(u, v):
        negative_samples.append((u, v))

# Calculate common neighbors
def common_neighbors(u, v):
    return len(list(nx.common_neighbors(G, u, v)))

# Create feature vectors
X = []
y = []
for u, v in positive_samples:
    X.append([common_neighbors(u, v)])
    y.append(1)
for u, v in negative_samples:
    X.append([common_neighbors(u, v)])
    y.append(0)

# Train a simple classifier
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
model = LogisticRegression()
model.fit(X_train, y_train)

# Evaluate the model
y_pred = model.predict(X_test)
print("ROC AUC Score:", roc_auc_score(y_test, y_pred))



